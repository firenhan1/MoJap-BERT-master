{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from glob import glob\n",
    "from typing import Optional\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import ConcatDataset\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForPermutationLanguageModeling,\n",
    "    HfArgumentParser,\n",
    "    LineByLineTextDataset,\n",
    "    PreTrainedTokenizer,\n",
    "    BertTokenizer,\n",
    "    TextDataset,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    BertConfig,\n",
    "    BertForMaskedLM\n",
    ")\n",
    "\n",
    "\n",
    "from datacollator import DataCollator\n",
    "from LineByLineDataset import LineByLineDataset\n",
    "# from BertJapaneseTokenizer import BertJapaneseTokenizer\n",
    "import TohokuBertCharJapaneseTokenizer\n",
    "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = TohokuBertCharJapaneseTokenizer.MecabCharacterBertTokenizer(vocab_file='vocab.txt', model_max_length=64, tokenize_chinese_chars=True)\n",
    "tokenizer = BertTokenizer(vocab_file='vocab.txt', model_max_length=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CandidatesOCR/example.txt']\n",
      "CandidatesOCR-rescore/example_rescore.txt\n",
      "list---------------  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-31 10:43:45.920425: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n",
      "2020-12-31 10:43:45.920447: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Traceback (most recent call last):\n",
      "  File \"get_score.py\", line 164, in <module>\n",
      "    main(args)\n",
      "  File \"get_score.py\", line 109, in main\n",
      "    print('list--------------- ', candidate_list)\n",
      "  File \"C:\\Users\\nhank\\anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode characters in position 43-45: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "!python get_score.py \\\n",
    "--input_file=\"CandidatesOCR/example.txt\" \\\n",
    "--model_path=\"output/\" \\\n",
    "--output_dir=\"CandidatesOCR-rescore/\" \\\n",
    "--model_max_length=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python find_candidates.py \\\n",
    "--input_file=\"CandidatesOCR/caption_train.txt\" \\\n",
    "--candidate_file=\"CandidatesOCR/train_decode_result_30k.txt\" \\\n",
    "--output_file=\"CandidatesOCR/output1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real text lines number:  4045\n",
      "text lines number more than 5 characters:  2746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-20 11:15:51.273580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n"
     ]
    }
   ],
   "source": [
    "!python count_text_more_5_char.py \\\n",
    "--input_file=\"CandidatesOCR/caption_val.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
